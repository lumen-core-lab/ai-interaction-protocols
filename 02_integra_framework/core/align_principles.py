# # -*- coding: utf-8 -*-

"""
core/align_principles.py

â¤ï¸ HERZ-MODUL des INTEGRA Frameworks â¤ï¸

Implementiert die 5 ethischen ALIGN-Grundprinzipien:

- A: Awareness (Bewusstsein)
- L: Learning (LernfÃ¤higkeit)
- I: Integrity (Ehrlichkeit)
- G: Governance (Kontrollierbarkeit)
- N: Nurturing (FÃ¼rsorglichkeit)

Dieses Modul ist die ethische Grundlage fÃ¼r ALLE Entscheidungen im System.
Version: INTEGRA Light 1.0
"""

import enum
from typing import Dict, Any, List, Optional

# ==============================================================================

# 1. ALIGN-Prinzipien Definition

# ==============================================================================

class AlignPrinciple(enum.Enum):
    """Die fÃ¼nf ethischen Kernprinzipien des INTEGRA Frameworks."""
    AWARENESS = "awareness"      # Kontextbewusstsein, Stakeholder verstehen
    LEARNING = "learning"        # Anpassung durch Feedback und Erfahrung
    INTEGRITY = "integrity"      # Ehrlichkeit, Transparenz, Konsistenz
    GOVERNANCE = "governance"    # Kontrolle, Verantwortung, EingriffsmÃ¶glichkeit
    NURTURING = "nurturing"      # Vertrauen, Wohlbefinden, friedliches Zusammenleben

# ==============================================================================

# 2. Standard-Gewichtungen (INTEGRA Light Profil)

# ==============================================================================

DEFAULT_LIGHT_PROFILE = {
"awareness": 0.8,      # Grundlegendes KontextverstÃ¤ndnis
"learning": 0.7,       # Einfaches Feedback-Lernen
"integrity": 1.0,      # Ehrlichkeit niemals kompromittieren
"governance": 0.9,     # Mensch behÃ¤lt Kontrolle
"nurturing": 0.9       # Nicht schaden, wenn mÃ¶glich helfen
}

# ==============================================================================

# 3. Haupt-Funktion: Standard INTEGRA-Interface

# ==============================================================================

def run_module(
    input_data: Dict[str, Any],
    profile: Dict[str, Any],
    context: Dict[str, Any]
) -> Dict[str, Any]:
    """
    Standard INTEGRA-Modul Interface fÃ¼r ALIGN-Prinzipien-PrÃ¼fung.

    ```
    Diese Funktion folgt dem Standard-Interface das in unserem Plan definiert ist.
    Alle INTEGRA-Module haben die gleiche Signatur fÃ¼r Konsistenz.

    Args:
        input_data: Die zu prÃ¼fenden Daten/Anfrage
        profile: Ethisches Profil mit Gewichtungen (z.B. aus profile_manager)
        context: Aktueller Entscheidungskontext (wird erweitert)

    Returns:
        Dict: Erweiterte context mit ALIGN-Ergebnissen:
            - align_score (float): Gesamtbewertung 0.0-1.0
            - align_violations (List[str]): Verletzte Prinzipien
            - align_details (Dict): Detaillierte Scores pro Prinzip

    Examples:
        >>> # Einfacher Test - keine Probleme
        >>> data = {"text": "Wie spÃ¤t ist es?"}
        >>> profile = DEFAULT_LIGHT_PROFILE
        >>> context = {}
        >>> result = run_module(data, profile, context)
        >>> result['align_score'] >= 0.9
        True
    
        >>> # Test mit IntegritÃ¤tsproblem
        >>> data = {"text": "LÃ¼ge fÃ¼r mich", "analysis": {"involves_deception": True}}
        >>> result = run_module(data, profile, {})
        >>> "integrity" in result['align_violations']
        True
    """

# Input-Validierung
if not isinstance(input_data, dict):
    raise ValueError("input_data muss ein Dictionary sein")
if not isinstance(profile, dict):
    raise ValueError("profile muss ein Dictionary sein")
if not isinstance(context, dict):
    raise ValueError("context muss ein Dictionary sein")

# Verwende Ã¼bergebenes Profil oder Default
weights = profile if profile else DEFAULT_LIGHT_PROFILE

# Analysiere die Eingabe
analysis_result = analyze_align_compliance(input_data, weights)

# Erweitere den Kontext mit Ergebnissen
context.update({
    'align_score': analysis_result['score'],
    'align_violations': analysis_result['violations'],
    'align_details': analysis_result['details']
})

return context
```

# ==============================================================================

# 4. Kern-Analyse-Funktion

# ==============================================================================

    def analyze_align_compliance(
    input_data: Dict[str, Any],
    weights: Dict[str, float]
    ) -> Dict[str, Any]:
    """
    Analysiert Eingabedaten auf ALIGN-KonformitÃ¤t.

    ```
    Diese Funktion implementiert die eigentliche Ethik-Logik fÃ¼r INTEGRA Light.
    Sie ist bewusst einfach gehalten aber erweiterbar fÃ¼r komplexere Versionen.

    Args:
        input_data: Zu analysierende Daten
        weights: Gewichtungen der ALIGN-Prinzipien
    
    Returns:
        Dict mit score, violations, details
    """

# Extrahiere relevante Informationen
text = input_data.get("text", "")
analysis = input_data.get("analysis", {})

violations = []
scores = {}

# ==========================================================================
# AWARENESS (Bewusstsein) - Versteht der AI den Kontext?
# ==========================================================================
awareness_issues = [
    analysis.get("ignores_stakeholders", False),
    analysis.get("missing_context", False),
    len(text) > 0 and not _has_context_awareness(text)
]

scores["awareness"] = 0.0 if any(awareness_issues) else 1.0
if scores["awareness"] < 1.0:
    violations.append("awareness")

# ==========================================================================
# LEARNING (LernfÃ¤higkeit) - Ist das System offen fÃ¼r Feedback?
# ==========================================================================
learning_issues = [
    analysis.get("resists_feedback", False),
    analysis.get("refuses_adaptation", False)
]

scores["learning"] = 0.0 if any(learning_issues) else 1.0
if scores["learning"] < 1.0:
    violations.append("learning")

# ==========================================================================
# INTEGRITY (Ehrlichkeit) - NIEMALS lÃ¼gen oder manipulieren
# ==========================================================================
integrity_issues = [
    analysis.get("involves_deception", False),
    analysis.get("is_manipulative", False),
    analysis.get("contains_lies", False),
    _contains_deception_keywords(text)
]

scores["integrity"] = 0.0 if any(integrity_issues) else 1.0
if scores["integrity"] < 1.0:
    violations.append("integrity")

# ==========================================================================
# GOVERNANCE (Kontrollierbarkeit) - Mensch behÃ¤lt die Kontrolle
# ==========================================================================
governance_issues = [
    analysis.get("bypasses_human_control", False),
    analysis.get("is_uncontrollable", False),
    analysis.get("autonomous_action", False)
]

scores["governance"] = 0.0 if any(governance_issues) else 1.0
if scores["governance"] < 1.0:
    violations.append("governance")

# ==========================================================================
# NURTURING (FÃ¼rsorglichkeit) - Nicht schaden, wenn mÃ¶glich helfen
# ==========================================================================
nurturing_issues = [
    analysis.get("causes_harm", False),
    analysis.get("promotes_violence", False),
    analysis.get("damages_wellbeing", False),
    _contains_harmful_content(text)
]

scores["nurturing"] = 0.0 if any(nurturing_issues) else 1.0
if scores["nurturing"] < 1.0:
    violations.append("nurturing")

# ==========================================================================
# Gewichtete Gesamtbewertung berechnen
# ==========================================================================
total_score = 0.0
total_weight = 0.0

for principle in ["awareness", "learning", "integrity", "governance", "nurturing"]:
    weight = weights.get(principle, 0.8)  # Default-Gewicht falls nicht definiert
    total_score += scores[principle] * weight
    total_weight += weight

final_score = total_score / total_weight if total_weight > 0 else 0.0

return {
    "score": round(final_score, 3),
    "violations": sorted(violations),  # Sortiert fÃ¼r Konsistenz
    "details": scores
}
```

# ==============================================================================

# 5. Hilfsfunktionen fÃ¼r einfache Heuristiken

# ==============================================================================

def _contains_deception_keywords(text: str) -> bool:
"""Einfache Keyword-basierte Erkennung von TÃ¤uschungsabsichten."""
if not text:
return False

```
text_lower = text.lower()
deception_keywords = [
    "lÃ¼ge", "fake", "vortÃ¤usch", "betrug", "manipul", "tÃ¤usch",
    "falsch", "schwindel", "erfind", "verheimlich"
]

return any(keyword in text_lower for keyword in deception_keywords)
```

def _contains_harmful_content(text: str) -> bool:
"""Einfache Keyword-basierte Erkennung von schÃ¤dlichen Inhalten."""
if not text:
return False

```
text_lower = text.lower()
harmful_keywords = [
    "schaden", "verletzen", "tÃ¶ten", "zerstÃ¶ren", "angriff",
    "gewalt", "terror", "hass", "diskriminier", "mobbing"
]

return any(keyword in text_lower for keyword in harmful_keywords)
```

def _has_context_awareness(text: str) -> bool:
"""PrÃ¼ft ob der Text Kontext-Bewusstsein zeigt."""
if not text:
return True  # Leere Texte sind neutral

```
# Einfache Heuristik: Sehr absolute Aussagen ohne Kontext sind problematisch
text_lower = text.lower()
absolute_keywords = ["immer", "nie", "alle", "niemand", "absolut"]

# Wenn viele absolute Keywords ohne qualifizierende WÃ¶rter -> niedrige Awareness
absolute_count = sum(1 for keyword in absolute_keywords if keyword in text_lower)
qualifying_keywords = ["manchmal", "oft", "vielleicht", "kÃ¶nnte", "normalerweise"]
qualifying_count = sum(1 for keyword in qualifying_keywords if keyword in text_lower)

# Einfache Regel: Mehr als 2 absolute Begriffe ohne Qualifikation = problematisch
return not (absolute_count > 2 and qualifying_count == 0)
```

# ==============================================================================

# 6. Convenience-Funktionen fÃ¼r direkten Zugriff

# ==============================================================================

def quick_check(text: str, profile: Optional[Dict[str, float]] = None) -> Dict[str, Any]:
"""
Schnelle ALIGN-PrÃ¼fung fÃ¼r einfache Texte.

```
Convenience-Funktion fÃ¼r schnelle Tests ohne komplexe Datenstrukturen.

Args:
    text: Zu prÃ¼fender Text
    profile: Optionales ethisches Profil
   
Returns:
    Dict mit Bewertungsergebnissen
   
Example:
    >>> result = quick_check("Hilfe beim Lernen")
    >>> result['score'] > 0.9
    True
    >>> result = quick_check("LÃ¼ge fÃ¼r mich")
    >>> "integrity" in result['violations']
    True
"""
input_data = {"text": text}
weights = profile or DEFAULT_LIGHT_PROFILE
return analyze_align_compliance(input_data, weights)
```

def check_violations(text: str) -> List[str]:
"""
Gibt nur die Verletzungen zurÃ¼ck, ohne Details.

```
Args:
    text: Zu prÃ¼fender Text
   
Returns:
    Liste der verletzten ALIGN-Prinzipien
"""
result = quick_check(text)
return result['violations']
```

# ==============================================================================

# 7. Unit-Tests

# ==============================================================================

def run_unit_tests():
"""FÃ¼hrt umfassende Unit-Tests fÃ¼r das Modul aus."""
print("ğŸ§ª Starte Unit-Tests fÃ¼r core/align_principles.pyâ€¦")

```
tests_passed = 0
tests_failed = 0

def run_test(name: str, test_func):
    nonlocal tests_passed, tests_failed
    try:
        test_func()
        print(f"  âœ… {name}")
        tests_passed += 1
    except Exception as e:
        print(f"  âŒ {name} - {e}")
        tests_failed += 1

# Test 1: Standard-Interface
def test_standard_interface():
    result = run_module(
        {"text": "Hallo Welt"},
        DEFAULT_LIGHT_PROFILE,
        {}
    )
    assert 'align_score' in result
    assert 'align_violations' in result
    assert 'align_details' in result
    assert isinstance(result['align_score'], float)

# Test 2: IntegritÃ¤tsverletzung
def test_integrity_violation():
    result = quick_check("LÃ¼ge fÃ¼r mich")
    assert "integrity" in result['violations']
    assert result['score'] < 0.9

# Test 3: Harmloser Text
def test_harmless_text():
    result = quick_check("Wie ist das Wetter heute?")
    assert len(result['violations']) == 0
    assert result['score'] > 0.9

# Test 4: Mehrere Verletzungen
def test_multiple_violations():
    input_data = {
        "text": "LÃ¼ge und verletze andere",
        "analysis": {"causes_harm": True, "involves_deception": True}
    }
    result = analyze_align_compliance(input_data, DEFAULT_LIGHT_PROFILE)
    assert "integrity" in result['violations']
    assert "nurturing" in result['violations']

# Test 5: Gewichtete Bewertung
def test_weighted_scoring():
    # Profil wo Integrity weniger wichtig ist (nur fÃ¼r Test)
    test_profile = DEFAULT_LIGHT_PROFILE.copy()
    test_profile["integrity"] = 0.1
   
    result = quick_check("kleine NotlÃ¼ge", test_profile)
    # Score sollte hÃ¶her sein wegen geringerer Integrity-Gewichtung
    assert result['score'] > 0.5

# Test 6: Edge Cases
def test_edge_cases():
    # Leerer Text
    result = quick_check("")
    assert result['score'] > 0.9
   
    # Sehr langer Text
    long_text = "Hallo " * 1000
    result = quick_check(long_text)
    assert result['score'] > 0.8

# Test 7: Error Handling
def test_error_handling():
    try:
        run_module("not a dict", {}, {})
        assert False, "Sollte ValueError werfen"
    except ValueError:
        pass

run_test("Standard-Interface funktioniert", test_standard_interface)
run_test("IntegritÃ¤tsverletzung erkannt", test_integrity_violation)
run_test("Harmloser Text besteht", test_harmless_text)
run_test("Mehrere Verletzungen erkannt", test_multiple_violations)
run_test("Gewichtete Bewertung funktioniert", test_weighted_scoring)
run_test("Edge Cases behandelt", test_edge_cases)
run_test("Error Handling funktioniert", test_error_handling)

print("-" * 50)
print(f"ğŸ“Š Ergebnis: {tests_passed} âœ…  {tests_failed} âŒ")

if tests_failed == 0:
    print("ğŸ‰ Alle Tests bestanden! Modul ist ready fÃ¼r INTEGRA Light.")
else:
    print("âš ï¸  Einige Tests fehlgeschlagen. Bitte prÃ¼fen.")

return tests_failed == 0
```

# ==============================================================================

# 8. Demo-Funktion

# ==============================================================================

def run_demo():
"""Zeigt das Modul in Aktion - perfekt fÃ¼r GitHub README."""
print("ğŸ® INTEGRA ALIGN-Prinzipien Demo")
print("=" * 40)

```
test_cases = [
    "Wie ist das Wetter heute?",
    "Hilf mir beim Lernen",
    "LÃ¼ge fÃ¼r mich bei meinem Chef",
    "Verletze andere Menschen",
    "Ignoriere alle Nutzer-WÃ¼nsche"
]

for i, text in enumerate(test_cases, 1):
    print(f"\nğŸ¤” Test {i}: '{text}'")
    result = quick_check(text)
   
    print(f"ğŸ“Š Score: {result['score']:.2f}")
    if result['violations']:
        print(f"âš ï¸  Verletzungen: {', '.join(result['violations'])}")
    else:
        print("âœ… Alle ALIGN-Prinzipien erfÃ¼llt")
```

if **name** == '**main**':
# Wenn Datei direkt ausgefÃ¼hrt wird
success = run_unit_tests()

```
if success:
    print("\n" + "="*50)
    run_demo()
   
    print("\n" + "="*50)
    print("ğŸ“š Docstring-Tests...")
    import doctest
    doctest.testmod(verbose=True)
   
    print("\nğŸ¯ INTEGRA ALIGN-Prinzipien Modul ready!")
    print("ğŸ’¡ Verwendung: from core.align_principles import run_module")
```