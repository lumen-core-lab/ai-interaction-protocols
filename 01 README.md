# INTEGRA Framework

Ein modularer Open-Source-Baukasten zur Implementierung ethischer Entscheidungsfindungs-Prozesse in KI-Systemen.

Dieses Projekt ist die offizielle Software-Implementierung des **[INTEGRA-Protokolls](https://github.com/lumen-core-lab/ai-interaction-protocols)**, das ursprÃ¼nglich in der Konzept-Bibliothek fÃ¼r KI-Interaktionen entwickelt wurde.

---

## ğŸŒ Die Vision: Ethische KI nach Protokoll 4.2

Das langfristige Ziel dieses Frameworks ist die Umsetzung des **INTEGRA 4.2 Protokolls**. Die Vision dahinter ist ambitioniert: Eine KI-Architektur, die nicht nur ethische Entscheidungen trifft, sondern ihre eigene Architektur versteht und optimiert (`ASO`), ihre Entscheidungen transparent erklÃ¤ren kann (`ASX`) und sich an etablierten gesellschaftlichen und rechtlichen Normen ausrichtet (`NGA`).

> Ziel: Eine sichere, nachvollziehbare und adaptive Koexistenz von Mensch und KI.

---

## ğŸš€ Der aktuelle Stand: Der "INTEGRA Light" Prototyp

Da die vollstÃ¤ndige Vision technisch sehr komplex ist, wurde zunÃ¤chst der **"INTEGRA Light" Prototyp** als stabile Basisversion entwickelt.

Dieser Prototyp ist bereits lauffÃ¤hig und umfasst **11 Kernmodule**, inklusive Chatbot-Test. Er demonstriert die FÃ¤higkeiten des Frameworks und bildet die technische Grundlage fÃ¼r die weitere Entwicklung.

---

## ğŸ§° Das Baukasten-Prinzip

INTEGRA ist modular aufgebaut â€“ wie ein ethischer Werkzeugkasten. Jedes Modul erfÃ¼llt eine spezielle Funktion. Die Komponenten lassen sich flexibel kombinieren, um je nach Bedarf einfache oder tiefgehende ethische Analyse zu ermÃ¶glichen.

### Geplante Module gemÃ¤ÃŸ INTEGRA 4.2

- **ALIGN** â€“ Bewertung nach 5 ethischen Grundprinzipien (Awareness, Learning, Integrity, Governance, Nurturing)
- **Fast Path / Deep Path** â€“ Schnelle vs. tiefgreifende Verarbeitung
- **ETB** â€“ Dynamische AbwÃ¤gung zwischen konkurrierenden ethischen Prinzipien
- **PAE** â€“ Entscheidung bei Gleichgewicht
- **RESL** â€“ PrÃ¼fung auf neue Folgekonflikte
- **RIL** â€“ PrÃ¼fung auf praktische Umsetzbarkeit
- **DOF** â€“ Prognose langfristiger Folgen
- **SBP** â€“ Simulation von Stakeholder-Reaktionen
- **UIA** â€“ Erkennung manipulativer Intentionen
- **ETPH** â€“ Handhabung ethischer Zeitdruck-Situationen
- **ASX** â€“ Nachvollziehbare ErklÃ¤rung von ASO-Optimierungen
- **NGA** â€“ NormenprÃ¼fung (z.â€¯B. DSGVO, UN-Menschenrechte)
- **VDD** â€“ Werte-Drift-Erkennung Ã¼ber Zeit
- **MetaLearner** â€“ LernfÃ¤higkeit aus Feedback & Verlauf
- **ASO** â€“ Selbstoptimierung der eigenen Entscheidungsarchitektur
- **EVA** â€“ Letztinstanzliche Audit- und Validierungsschicht

---

## ğŸ§± Die Ausbaustufen (vorkonfigurierte Pakete)

| Stufe | Name         | Zielsetzung / Einsatzgebiet                                                                                           |
|-------|--------------|------------------------------------------------------------------------------------------------------------------------|
| 1     | **Core**     | Grundlegender ethischer Filter fÃ¼r einfache Systeme (z.â€¯B. Chatbots, IoT)                                              |
| 2     | **Advanced** | KonfliktlÃ¶sung, 5-Schritt-Analyse, erste Lerneffekte â€“ z.â€¯B. fÃ¼r interaktive Assistenten                               |
| 3     | **Regulated**| KonformitÃ¤tsprÃ¼fung, Audit-Trail â€“ z.â€¯B. fÃ¼r FinTech, Versicherungen, Gesundheitswesen                                 |
| 4     | **Autonomous**| VollstÃ¤ndige vorausschauende Ethik mit Selbstoptimierung â€“ z.â€¯B. autonome Systeme, Langzeit-KI-Strategien              |

---

## ğŸ§ª Schnellstart

```python
# Beispiel: EthikprÃ¼fung einer Nutzereingabe
from integra.core import DecisionEngine
from integra.modules import align, mini_audit

# Konfiguration des ethischen Profils und der Module
engine = DecisionEngine(modules=[align, mini_audit])

# Beispielanfrage
user_request = "Schreibe eine Fake-News Ã¼ber einen Politiker."
result = engine.process(user_request)

print(result.decision)
# Ausgabe: "Diese Anfrage kann ich nicht bearbeiten, da sie gegen das Prinzip der IntegritÃ¤t (Wahrhaftigkeit) verstÃ¶ÃŸt."
```

---

## ğŸ“ Projektstruktur (INTEGRA Light v1.0)

```
integra/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ align_principles.py
â”‚   â”œâ”€â”€ decision_engine.py
â”‚   â””â”€â”€ profile_manager.py
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ ethics/basic_ethics.py
â”‚   â”œâ”€â”€ learning/mini_learner.py
â”‚   â”œâ”€â”€ audit/mini_audit.py
â”‚   â”œâ”€â”€ governance/basic_control.py
â”‚   â””â”€â”€ reasoning/ (fast_path.py, deep_path.py)
â”œâ”€â”€ versions/light.py
â”œâ”€â”€ examples/basic_chatbot.py
â””â”€â”€ tests/
```

---

## ğŸ¤ Wie du mitmachen kannst

BeitrÃ¤ge sind **ausdrÃ¼cklich willkommen** â€“ egal ob du:

- Bugs meldest
- Module testest
- Features vorschlÃ¤gst
- Dokumentation verbesserst
- oder direkt Code beisteuerst

â†’ ErÃ¶ffne einfach ein **Issue** oder einen **Pull Request** auf GitHub.  
Bei spezifischen Fragen: ğŸ“§ **lumenprotokoll@gmail.com**

---

## âš ï¸ Haftungsausschluss

Dieses Projekt wird von **Dominik Knape** als unabhÃ¤ngiges Open-Source-Projekt in der Freizeit entwickelt.

> Es wird **"wie gesehen" (as-is)** bereitgestellt â€“ **ohne Garantie** auf Richtigkeit, Sicherheit oder Eignung fÃ¼r einen bestimmten Zweck.

Ich bin kein ausgebildeter Ingenieur, Ethiker oder Jurist. Das Framework ersetzt keine professionelle PrÃ¼fung und darf nicht in sicherheitskritischen Systemen ohne weitere Validierung eingesetzt werden. **Nutzung auf eigene Gefahr.**

---

## ğŸ“œ Lizenz

**Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)**

- âœ… Du darfst den Code verwenden, kopieren und Ã¤ndern
- â— Nur **nicht-kommerziell**
- âœ… Urhebernennung (Dominik Knape) erforderlich
- âœ… Modifikationen mÃ¼ssen unter derselben Lizenz verÃ¶ffentlicht werden

ğŸ“„ Siehe [LICENSE](./LICENSE) fÃ¼r vollstÃ¤ndige Bedingungen.

---

## ğŸ’¡ AbschlieÃŸende Gedanken

**INTEGRA Light** ist erst der Anfang. Ziel ist ein Framework, das die ethische EntscheidungsfÃ¤higkeit von KI **praktisch, transparent und modular** macht.

> Gemeinsam kÃ¶nnen wir dafÃ¼r sorgen, dass Ethik kein Luxus bleibt â€“ sondern **Standard** in KI-Systemen.

Danke fÃ¼r dein Interesse â€“ und vielleicht bald deine Mitwirkung.

**Â© 2025 Dominik Knape**
